# üìö MARCO TE√ìRICO - APRENDIZAJE EN LA WEB

## 1. INTRODUCCI√ìN

### ¬øQu√© es el Aprendizaje en la Web?

El **Aprendizaje en la Web** (Web Learning) es una rama del Machine Learning que se enfoca en extraer, procesar y aprender de datos disponibles en internet. Combina t√©cnicas de:

- **Web Scraping**: Extracci√≥n automatizada de contenido web
- **Procesamiento de Lenguaje Natural (NLP)**: An√°lisis y comprensi√≥n de texto
- **Machine Learning**: Aprendizaje de patrones y predicci√≥n
- **Miner√≠a de Datos**: Descubrimiento de conocimiento en grandes vol√∫menes de informaci√≥n

---

## 2. COMPONENTES FUNDAMENTALES

### 2.1 Web Scraping

**Definici√≥n**: Proceso automatizado de extracci√≥n de informaci√≥n de sitios web.

**T√©cnicas principales:**
- **Parsing HTML**: An√°lisis de estructura DOM (Document Object Model)
- **Selectores CSS**: Identificaci√≥n de elementos espec√≠ficos
- **XPath**: Navegaci√≥n en documentos XML/HTML
- **APIs Web**: Acceso estructurado a datos

**Herramientas en Python:**
```
‚Ä¢ BeautifulSoup: Parsing HTML/XML
‚Ä¢ Scrapy: Framework completo de scraping
‚Ä¢ Selenium: Scraping de p√°ginas din√°micas (JavaScript)
‚Ä¢ Requests: Peticiones HTTP
```

**Consideraciones √©ticas:**
- Respetar el archivo `robots.txt`
- No sobrecargar servidores (rate limiting)
- Cumplir con t√©rminos de servicio
- Respetar derechos de autor

---

### 2.2 Procesamiento de Lenguaje Natural (NLP)

**Definici√≥n**: Campo de la IA que permite a las computadoras entender, interpretar y generar lenguaje humano.

#### Pipeline t√≠pico de NLP:

**1. Tokenizaci√≥n**
```
Texto: "Python es genial"
Tokens: ["Python", "es", "genial"]
```

**2. Normalizaci√≥n**
- Convertir a min√∫sculas
- Eliminar puntuaci√≥n
- Eliminar caracteres especiales

**3. Stopwords Removal**
```
Texto: ["el", "python", "es", "un", "lenguaje"]
Filtrado: ["python", "lenguaje"]
```
*Elimina palabras comunes sin valor sem√°ntico*

**4. Stemming / Lemmatization**
```
Stemming: "corriendo" ‚Üí "corr"
Lemmatization: "corriendo" ‚Üí "correr"
```

**5. Vectorizaci√≥n**
Convertir texto en n√∫meros que las m√°quinas pueden procesar.

**T√©cnicas de vectorizaci√≥n:**

a) **Bag of Words (BoW)**
```
Documento 1: "me gusta python"
Documento 2: "python es genial"

Vocabulario: [me, gusta, python, es, genial]

Vector 1: [1, 1, 1, 0, 0]
Vector 2: [0, 0, 1, 1, 1]
```

b) **TF-IDF (Term Frequency - Inverse Document Frequency)**
```
TF-IDF = TF √ó IDF

TF (Term Frequency): 
   Frecuencia de t√©rmino en el documento

IDF (Inverse Document Frequency): 
   log(Total documentos / Documentos con el t√©rmino)

Ventaja: Palabras comunes tienen menor peso
```

c) **Word Embeddings**
- Word2Vec
- GloVe
- FastText
- Transformers (BERT, GPT)

---

### 2.3 Machine Learning para Texto

#### Clasificaci√≥n de Texto

**Definici√≥n**: Asignar categor√≠as predefinidas a documentos.

**Algoritmos comunes:**

1. **Naive Bayes**
   - Basado en probabilidad bayesiana
   - R√°pido y eficiente
   - Funciona bien con datasets peque√±os
   - Asume independencia entre caracter√≠sticas

   ```
   P(Categor√≠a|Texto) = P(Texto|Categor√≠a) √ó P(Categor√≠a) / P(Texto)
   ```

2. **Support Vector Machines (SVM)**
   - Encuentra el hiperplano que mejor separa las clases
   - Efectivo en espacios de alta dimensi√≥n
   - Robusto contra overfitting

3. **Random Forest**
   - Conjunto de √°rboles de decisi√≥n
   - Reduce overfitting
   - Maneja caracter√≠sticas no lineales

4. **Redes Neuronales**
   - Deep Learning para texto
   - LSTM, GRU para secuencias
   - Transformers para tareas complejas

**M√©tricas de evaluaci√≥n:**

- **Accuracy (Precisi√≥n)**: 
  ```
  (Predicciones correctas) / (Total predicciones)
  ```

- **Precision**: 
  ```
  Verdaderos positivos / (Verdaderos positivos + Falsos positivos)
  ```

- **Recall (Sensibilidad)**: 
  ```
  Verdaderos positivos / (Verdaderos positivos + Falsos negativos)
  ```

- **F1-Score**: 
  ```
  2 √ó (Precision √ó Recall) / (Precision + Recall)
  ```

#### Clustering (Agrupamiento)

**Definici√≥n**: Agrupar documentos similares sin etiquetas previas (aprendizaje no supervisado).

**Algoritmos:**

1. **K-Means**
   - Define K clusters
   - Asigna documentos al centroide m√°s cercano
   - Itera hasta convergencia

2. **DBSCAN**
   - Agrupa por densidad
   - Detecta outliers autom√°ticamente

3. **Clustering Jer√°rquico**
   - Crea dendrogramas
   - Agrupa progresivamente

**M√©tricas de clustering:**

- **Silhouette Score**: 
  - Rango: [-1, 1]
  - Valores cercanos a 1 = buen agrupamiento
  - Valores negativos = mala asignaci√≥n

---

## 3. ARQUITECTURA DEL SISTEMA

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ENTRADA DE DATOS                      ‚îÇ
‚îÇ  ‚Ä¢ URLs de sitios web                                    ‚îÇ
‚îÇ  ‚Ä¢ Texto directo                                         ‚îÇ
‚îÇ  ‚Ä¢ Archivos (CSV, TXT, JSON)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              1. WEB SCRAPING / RECOLECCI√ìN              ‚îÇ
‚îÇ  ‚Ä¢ Requests HTTP                                         ‚îÇ
‚îÇ  ‚Ä¢ Parsing HTML (BeautifulSoup)                         ‚îÇ
‚îÇ  ‚Ä¢ Extracci√≥n de texto relevante                        ‚îÇ
‚îÇ  ‚Ä¢ Limpieza b√°sica                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              2. PREPROCESAMIENTO (NLP)                   ‚îÇ
‚îÇ  ‚Ä¢ Tokenizaci√≥n                                          ‚îÇ
‚îÇ  ‚Ä¢ Normalizaci√≥n (lowercase, sin puntuaci√≥n)            ‚îÇ
‚îÇ  ‚Ä¢ Eliminaci√≥n de stopwords                             ‚îÇ
‚îÇ  ‚Ä¢ Stemming / Lemmatization                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              3. VECTORIZACI√ìN                            ‚îÇ
‚îÇ  ‚Ä¢ TF-IDF Vectorizer                                     ‚îÇ
‚îÇ  ‚Ä¢ Bag of Words                                          ‚îÇ
‚îÇ  ‚Ä¢ Word Embeddings (opcional)                           ‚îÇ
‚îÇ  Salida: Matriz de caracter√≠sticas num√©ricas            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              4. ENTRENAMIENTO DEL MODELO                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  OPCI√ìN A: Clasificaci√≥n Supervisada                    ‚îÇ
‚îÇ  ‚Ä¢ Naive Bayes / SVM / Random Forest                    ‚îÇ
‚îÇ  ‚Ä¢ Train/Test Split                                      ‚îÇ
‚îÇ  ‚Ä¢ Evaluaci√≥n con m√©tricas                              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  OPCI√ìN B: Clustering No Supervisado                    ‚îÇ
‚îÇ  ‚Ä¢ K-Means / DBSCAN                                      ‚îÇ
‚îÇ  ‚Ä¢ Agrupamiento autom√°tico                              ‚îÇ
‚îÇ  ‚Ä¢ An√°lisis de clusters                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              5. PREDICCI√ìN / INFERENCIA                  ‚îÇ
‚îÇ  ‚Ä¢ Texto nuevo ‚Üí Preprocesar                            ‚îÇ
‚îÇ  ‚Ä¢ Vectorizar                                            ‚îÇ
‚îÇ  ‚Ä¢ Aplicar modelo entrenado                             ‚îÇ
‚îÇ  ‚Ä¢ Obtener categor√≠a/cluster                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              6. VISUALIZACI√ìN Y AN√ÅLISIS                 ‚îÇ
‚îÇ  ‚Ä¢ M√©tricas de rendimiento                              ‚îÇ
‚îÇ  ‚Ä¢ Gr√°ficos de distribuci√≥n                             ‚îÇ
‚îÇ  ‚Ä¢ Matriz de confusi√≥n                                  ‚îÇ
‚îÇ  ‚Ä¢ Palabras m√°s relevantes                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 4. APLICACIONES PR√ÅCTICAS

### 4.1 Clasificaci√≥n Autom√°tica de Contenido
- Categorizaci√≥n de noticias por tema
- Filtrado de spam en correos
- Clasificaci√≥n de tickets de soporte

### 4.2 An√°lisis de Sentimientos
- Opiniones en redes sociales
- Reviews de productos
- Monitoreo de marca

### 4.3 Recomendaci√≥n de Contenido
- Sugerencias de art√≠culos similares
- Sistemas de recomendaci√≥n
- B√∫squeda sem√°ntica

### 4.4 Detecci√≥n de Temas
- Identificar tendencias en redes
- An√°lisis de t√≥picos (Topic Modeling)
- Vigilancia de informaci√≥n

### 4.5 Extracci√≥n de Informaci√≥n
- Obtener datos estructurados de texto
- Named Entity Recognition (NER)
- Resumen autom√°tico de documentos

---

## 5. DESAF√çOS Y CONSIDERACIONES

### 5.1 Desaf√≠os T√©cnicos
- **Escalabilidad**: Procesar grandes vol√∫menes de datos
- **Ruido en datos web**: HTML mal formado, publicidad
- **Ambig√ºedad del lenguaje**: Sarcasmo, iron√≠a, contexto
- **Multiling√ºismo**: Soporte para m√∫ltiples idiomas
- **Datos desbalanceados**: Categor√≠as con pocos ejemplos

### 5.2 Desaf√≠os √âticos
- Privacidad de datos
- Sesgos en modelos de ML
- Derechos de autor del contenido
- Uso responsable de informaci√≥n

### 5.3 Mejores Pr√°cticas
- Validaci√≥n cruzada (k-fold cross-validation)
- Regularizaci√≥n para evitar overfitting
- Monitoreo continuo del modelo
- Reentrenamiento peri√≥dico
- Documentaci√≥n exhaustiva

---

## 6. TENDENCIAS ACTUALES

### 6.1 Transfer Learning
- Usar modelos preentrenados (BERT, GPT)
- Fine-tuning para tareas espec√≠ficas
- Menor necesidad de datos

### 6.2 Few-Shot Learning
- Aprender con pocos ejemplos
- Meta-learning
- Prompt engineering

### 6.3 Multimodalidad
- Combinar texto, im√°genes, audio
- Modelos como CLIP, DALL-E
- Comprensi√≥n hol√≠stica del contenido

### 6.4 Explicabilidad (XAI)
- Entender decisiones del modelo
- LIME, SHAP para interpretabilidad
- Confianza en predicciones

---

## 7. HERRAMIENTAS Y FRAMEWORKS

### Python Libraries:
- **Web Scraping**: BeautifulSoup, Scrapy, Selenium
- **NLP**: NLTK, spaCy, TextBlob
- **Machine Learning**: scikit-learn, XGBoost
- **Deep Learning**: TensorFlow, PyTorch, Keras
- **Visualizaci√≥n**: Matplotlib, Seaborn, Plotly
- **Web Apps**: Streamlit, Flask, FastAPI

### Cloud Services:
- **AWS**: SageMaker, Comprehend
- **Google Cloud**: Natural Language API, AutoML
- **Azure**: Cognitive Services

---

## 8. M√âTRICAS DE √âXITO

Para evaluar un sistema de aprendizaje web:

1. **Precisi√≥n del modelo** (>85% es bueno)
2. **Velocidad de procesamiento** (documentos/segundo)
3. **Escalabilidad** (capacidad de crecer)
4. **Facilidad de uso** (interfaz intuitiva)
5. **Interpretabilidad** (entender predicciones)
6. **Robustez** (manejar datos ruidosos)

---

## 9. CONCLUSI√ìN

El aprendizaje en la web es un campo interdisciplinario que combina:
- Ingenier√≠a de software
- Ciencia de datos
- Ling√º√≠stica computacional
- Estad√≠stica y matem√°ticas

**Ventajas:**
- Acceso a grandes vol√∫menes de datos
- Automatizaci√≥n de tareas repetitivas
- Descubrimiento de patrones ocultos
- Escalabilidad

**Limitaciones:**
- Dependencia de la calidad de datos
- Necesidad de etiquetado (aprendizaje supervisado)
- Mantenimiento continuo
- Consideraciones √©ticas

---

## 10. REFERENCIAS Y RECURSOS

### Libros:
- "Speech and Language Processing" - Jurafsky & Martin
- "Introduction to Information Retrieval" - Manning et al.
- "Python Machine Learning" - Sebastian Raschka

### Cursos Online:
- Coursera: Natural Language Processing Specialization
- Fast.ai: Practical Deep Learning
- DataCamp: NLP in Python

### Papers Importantes:
- "Attention Is All You Need" (Transformers)
- "BERT: Pre-training of Deep Bidirectional Transformers"
- "Efficient Estimation of Word Representations" (Word2Vec)

---

**√öltima actualizaci√≥n:** Noviembre 2024

---

## GLOSARIO DE T√âRMINOS

- **Corpus**: Colecci√≥n de documentos de texto
- **Token**: Unidad m√≠nima de texto (palabra, car√°cter)
- **Feature**: Caracter√≠stica extra√≠da del texto
- **Label**: Etiqueta o categor√≠a de clasificaci√≥n
- **Training Set**: Conjunto de datos para entrenar
- **Test Set**: Conjunto de datos para evaluar
- **Overfitting**: Modelo aprende ruido del training
- **Underfitting**: Modelo demasiado simple
- **Hyperparameter**: Par√°metro que se ajusta antes del entrenamiento
- **Pipeline**: Secuencia de pasos de procesamiento
