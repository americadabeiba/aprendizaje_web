"""
=======================================================
M√ìDULO 4: APLICACI√ìN WEB - Interfaz Streamlit
=======================================================
Aplicaci√≥n web interactiva para demostrar el sistema
"""

import streamlit as st
import pandas as pd
import numpy as np
import sys
import os

# A√±adir el directorio src al path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from scraping import WebScraper
from preprocessing import PreprocesadorTexto
from model import ModeloAprendizajeWeb
import plotly.express as px
import plotly.graph_objects as go


# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Sistema de Aprendizaje Web",
    page_icon="üåê",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1E88E5;
        text-align: center;
        padding: 1rem 0;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #424242;
        text-align: center;
        padding-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .stButton>button {
        width: 100%;
        background-color: #1E88E5;
        color: white;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


def inicializar_sesion():
    """Inicializa variables de sesi√≥n"""
    if 'scraper' not in st.session_state:
        st.session_state.scraper = WebScraper()
    if 'preprocesador' not in st.session_state:
        st.session_state.preprocesador = PreprocesadorTexto()
    if 'modelo' not in st.session_state:
        st.session_state.modelo = ModeloAprendizajeWeb()
    if 'datos' not in st.session_state:
        st.session_state.datos = None
    if 'modelo_entrenado' not in st.session_state:
        st.session_state.modelo_entrenado = False


def pagina_inicio():
    """P√°gina principal con informaci√≥n del sistema"""
    st.markdown('<h1 class="main-header">üåê Sistema de Aprendizaje en la Web</h1>', 
                unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Extrae, Procesa y Aprende de Contenido Web Autom√°ticamente</p>', 
                unsafe_allow_html=True)
    
    # Descripci√≥n del sistema
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### üì• 1. Extracci√≥n
        El sistema extrae contenido de p√°ginas web utilizando t√©cnicas de **web scraping**.
        
        - Extrae texto de URLs
        - Limpia HTML
        - Identifica contenido relevante
        """)
    
    with col2:
        st.markdown("""
        ### üîß 2. Procesamiento
        Preprocesa el texto usando t√©cnicas de **NLP** (Procesamiento de Lenguaje Natural).
        
        - Tokenizaci√≥n
        - Eliminaci√≥n de stopwords
        - Vectorizaci√≥n TF-IDF
        """)
    
    with col3:
        st.markdown("""
        ### ü§ñ 3. Aprendizaje
        Aplica modelos de **Machine Learning** para clasificar y agrupar contenido.
        
        - Clasificaci√≥n supervisada
        - Clustering autom√°tico
        - Predicciones en tiempo real
        """)
    
    st.divider()
    
    # Flujo del sistema
    st.subheader("üîÑ Flujo del Sistema")
    
    flow_diagram = """
    ```
    URL/Texto ‚Üí Web Scraping ‚Üí Preprocesamiento ‚Üí Vectorizaci√≥n ‚Üí Modelo ML ‚Üí Resultados
    ```
    """
    st.markdown(flow_diagram)
    
    # Instrucciones
    st.info("""
    üëà **Usa el men√∫ lateral para navegar:**
    - **Extracci√≥n de Datos**: Extrae contenido de URLs
    - **Entrenamiento**: Entrena modelos de clasificaci√≥n
    - **Predicci√≥n**: Clasifica nuevo contenido
    - **An√°lisis**: Visualiza resultados y estad√≠sticas
    """)


def pagina_extraccion():
    """P√°gina para extraer datos de la web"""
    st.header("üì• Extracci√≥n de Datos Web")
    
    # Opciones de extracci√≥n
    modo = st.radio(
        "Selecciona el modo de extracci√≥n:",
        ["URLs individuales", "Texto directo", "Dataset de ejemplo"]
    )
    
    if modo == "URLs individuales":
        st.subheader("Ingresa las URLs a extraer")
        
        urls_text = st.text_area(
            "URLs (una por l√≠nea):",
            height=150,
            placeholder="https://ejemplo.com/articulo1\nhttps://ejemplo.com/articulo2"
        )
        
        if st.button("üöÄ Extraer Contenido"):
            if urls_text:
                urls = [url.strip() for url in urls_text.split('\n') if url.strip()]
                
                with st.spinner(f"Extrayendo contenido de {len(urls)} URLs..."):
                    df = st.session_state.scraper.extraer_multiples_urls(urls)
                    st.session_state.datos = df
                
                if not df.empty:
                    st.success(f"‚úÖ Se extrajeron {len(df)} documentos exitosamente")
                    
                    # Verificar si hay categor√≠as
                    if 'categoria' not in df.columns:
                        st.warning("""
                        ‚ö†Ô∏è **Nota importante:** Los datos extra√≠dos no tienen categor√≠as asignadas.
                        """)
                        
                        # NUEVO: Bot√≥n de categorizaci√≥n autom√°tica
                        st.info("""
                        üí° **¬°Prueba la categorizaci√≥n autom√°tica!**
                        
                        Usa inteligencia artificial para identificar autom√°ticamente 
                        las categor√≠as de tus documentos sin necesidad de etiquetarlos manualmente.
                        """)
                        
                        col1, col2 = st.columns([1, 3])
                        with col1:
                            if st.button("ü§ñ Categorizar Autom√°ticamente", type="primary"):
                                with st.spinner("Analizando contenido y detectando categor√≠as..."):
                                    from categorizador_auto import CategorizadorAutomatico
                                    from preprocessing import PreprocesadorTexto
                                    
                                    # Preprocesar si no est√° ya procesado
                                    if 'texto_procesado' not in df.columns:
                                        prep = PreprocesadorTexto()
                                        df['texto_procesado'] = df['texto'].apply(prep.procesar_texto)
                                    
                                    # Categorizar
                                    categorizador = CategorizadorAutomatico()
                                    df = categorizador.analizar_y_categorizar(df)
                                    
                                    # Renombrar columna
                                    df['categoria'] = df['categoria_auto']
                                    
                                    # Actualizar en session state
                                    st.session_state.datos = df
                                    
                                    st.success("‚úÖ ¬°Categorizaci√≥n autom√°tica completada!")
                                    st.rerun()
                        
                        with col2:
                            st.markdown("""
                            **Alternativas manuales:**
                            1. Usar el **Dataset de ejemplo** que ya tiene categor√≠as
                            2. Agregar documentos con **"Texto directo"** y seleccionar categor√≠as
                            """)
                    
                    st.dataframe(df)
                    
                    # Estad√≠sticas
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìÑ Total Documentos", len(df))
                    with col2:
                        st.metric("üìä Promedio Palabras", int(df['longitud'].mean()))
                    with col3:
                        st.metric("üìù Total Palabras", int(df['longitud'].sum()))
                else:
                    st.error("‚ùå No se pudo extraer contenido")
            else:
                st.warning("‚ö†Ô∏è Por favor ingresa al menos una URL")
    
    elif modo == "Texto directo":
        st.subheader("Ingresa texto manualmente")
        
        col1, col2 = st.columns(2)
        with col1:
            titulo = st.text_input("T√≠tulo del documento:")
        with col2:
            # Opci√≥n de categor√≠a manual o autom√°tica
            modo_categoria = st.radio(
                "Modo de categor√≠a:",
                ["Manual", "Autom√°tica"],
                horizontal=True,
                help="Manual: T√∫ seleccionas la categor√≠a. Autom√°tica: IA la detecta."
            )
        
        texto = st.text_area("Contenido:", height=200)
        
        # Mostrar selector de categor√≠a solo si es manual
        if modo_categoria == "Manual":
            categoria = st.selectbox("Categor√≠a:", 
                                    ["Tecnolog√≠a", "Ciencia", "Deportes", "Pol√≠tica", 
                                     "M√∫sica", "Arte", "Literatura", "Cine", "Otro"])
        else:
            st.info("üí° La categor√≠a se detectar√° autom√°ticamente al agregar el documento")
            categoria = None
        
        if st.button("‚ûï Agregar Documento"):
            if titulo and texto:
                # Si es autom√°tica, detectar la categor√≠a
                if modo_categoria == "Autom√°tica":
                    with st.spinner("Detectando categor√≠a..."):
                        from categorizador_auto import CategorizadorAutomatico
                        from preprocessing import PreprocesadorTexto
                        
                        prep = PreprocesadorTexto()
                        texto_procesado = prep.procesar_texto(texto)
                        
                        categorizador = CategorizadorAutomatico()
                        categoria_detectada, confianza = categorizador.detectar_categoria_por_keywords(texto_procesado)
                        
                        categoria = categoria_detectada
                        st.success(f"‚úÖ Categor√≠a detectada: **{categoria}** (confianza: {confianza:.2f})")
                
                nuevo_doc = pd.DataFrame([{
                    'titulo': titulo,
                    'texto': texto,
                    'categoria': categoria,
                    'longitud': len(texto.split())
                }])
                
                if st.session_state.datos is None:
                    st.session_state.datos = nuevo_doc
                else:
                    st.session_state.datos = pd.concat(
                        [st.session_state.datos, nuevo_doc], 
                        ignore_index=True
                    )
                
                st.success("‚úÖ Documento agregado correctamente")
                st.dataframe(st.session_state.datos)
            else:
                st.warning("‚ö†Ô∏è Por favor completa todos los campos")
    
    else:  # Dataset de ejemplo
        st.subheader("Cargar Dataset de Ejemplo")
        st.info("Este dataset contiene art√≠culos de ejemplo pre-clasificados")
        
        if st.button("üì¶ Cargar Dataset de Ejemplo"):
            # Crear dataset sint√©tico
            df_ejemplo = crear_dataset_ejemplo()
            st.session_state.datos = df_ejemplo
            
            st.success(f"‚úÖ Dataset cargado: {len(df_ejemplo)} documentos")
            st.dataframe(df_ejemplo)
            
            # Visualizar distribuci√≥n
            fig = px.histogram(df_ejemplo, x='categoria', 
                             title='Distribuci√≥n de Documentos por Categor√≠a')
            st.plotly_chart(fig, use_container_width=True)


def crear_dataset_ejemplo():
    """Crea un dataset de ejemplo para demostraci√≥n"""
    datos = {
        'titulo': [
            'Inteligencia Artificial en la Medicina',
            'Nuevos Algoritmos de Machine Learning',
            'Python para Ciencia de Datos',
            'Campeonato Mundial de F√∫tbol 2024',
            'Los Mejores Jugadores de Basketball',
            'T√©cnicas de Entrenamiento Deportivo',
            'Descubrimiento en F√≠sica Cu√°ntica',
            'Avances en Biolog√≠a Molecular',
            'Nueva Teor√≠a sobre el Universo'
        ],
        'texto': [
            'La inteligencia artificial est√° transformando el diagn√≥stico m√©dico mediante algoritmos avanzados de aprendizaje profundo que analizan im√°genes y datos cl√≠nicos.',
            'Los nuevos algoritmos de machine learning permiten procesar grandes vol√∫menes de datos con mayor precisi√≥n y eficiencia en tiempo real.',
            'Python se ha consolidado como el lenguaje preferido para an√°lisis de datos gracias a bibliotecas como pandas numpy y scikit-learn.',
            'El campeonato mundial de f√∫tbol re√∫ne a las mejores selecciones del planeta en un torneo emocionante con millones de espectadores.',
            'Los jugadores de basketball m√°s destacados demuestran habilidades excepcionales en cancha y lideran a sus equipos hacia la victoria.',
            'Las t√©cnicas modernas de entrenamiento deportivo combinan ciencia ejercicio y nutrici√≥n para optimizar el rendimiento de los atletas.',
            'Cient√≠ficos han logrado avances significativos en f√≠sica cu√°ntica que podr√≠an revolucionar la computaci√≥n y las comunicaciones.',
            'La investigaci√≥n en biolog√≠a molecular revela nuevos mecanismos celulares que abren posibilidades para tratamientos m√©dicos innovadores.',
            'Una nueva teor√≠a cosmol√≥gica propone explicaciones alternativas sobre la formaci√≥n y evoluci√≥n del universo observable.'
        ],
        'categoria': [
            'Tecnolog√≠a', 'Tecnolog√≠a', 'Tecnolog√≠a',
            'Deportes', 'Deportes', 'Deportes',
            'Ciencia', 'Ciencia', 'Ciencia'
        ]
    }
    
    df = pd.DataFrame(datos)
    df['longitud'] = df['texto'].apply(lambda x: len(x.split()))
    return df


def pagina_entrenamiento():
    """P√°gina para entrenar modelos"""
    st.header("ü§ñ Entrenamiento de Modelos")
    
    if st.session_state.datos is None or st.session_state.datos.empty:
        st.warning("‚ö†Ô∏è Primero debes extraer o cargar datos en la secci√≥n 'Extracci√≥n de Datos'")
        return
    
    st.subheader("Datos Disponibles")
    st.dataframe(st.session_state.datos)
    
    # Verificar si hay columna de categor√≠as
    if 'categoria' not in st.session_state.datos.columns:
        st.error("""
        ‚ùå **Los datos no tienen etiquetas de categor√≠a**
        
        ### Para poder entrenar un modelo necesitas:
        
        **Opci√≥n 1: Usar el Dataset de Ejemplo**
        - Ve a **"Extracci√≥n de Datos"**
        - Selecciona **"Dataset de ejemplo"**
        - Carga el dataset (tiene 9 documentos con 3 categor√≠as)
        
        **Opci√≥n 2: Agregar Categor√≠as Manualmente**
        - Ve a **"Extracci√≥n de Datos"**
        - Usa **"Texto directo"** para agregar documentos con categor√≠as
        
        **Opci√≥n 3: Editar el CSV**
        - Descarga los datos actuales
        - Agrega una columna "categoria" en Excel
        - Vuelve a cargar el archivo (implementaci√≥n futura)
        
        **Opci√≥n 4: Usar Clustering (No Supervisado)**
        - El clustering NO requiere categor√≠as
        - Agrupa documentos similares autom√°ticamente
        - (Implementaci√≥n futura en esta app)
        """)
        return
    
    st.divider()
    
    # Preprocesamiento
    st.subheader("1Ô∏è‚É£ Preprocesamiento de Texto")
    
    if st.button("üîß Procesar Textos"):
        with st.spinner("Procesando textos..."):
            prep = st.session_state.preprocesador
            
            # Procesar cada texto
            textos_procesados = []
            for texto in st.session_state.datos['texto']:
                texto_proc = prep.procesar_texto(texto)
                textos_procesados.append(texto_proc)
            
            st.session_state.datos['texto_procesado'] = textos_procesados
            
            # Vectorizar
            st.session_state.vectores = prep.vectorizar_textos(textos_procesados)
            
            st.success("‚úÖ Preprocesamiento completado")
            
            # Mostrar ejemplo
            with st.expander("Ver ejemplo de procesamiento"):
                idx = 0
                st.write("**Texto original:**")
                st.write(st.session_state.datos.iloc[idx]['texto'][:200] + "...")
                st.write("**Texto procesado:**")
                st.write(st.session_state.datos.iloc[idx]['texto_procesado'])
    
    st.divider()
    
    # Entrenamiento
    st.subheader("2Ô∏è‚É£ Entrenar Modelo de Clasificaci√≥n")
    
    if 'vectores' not in st.session_state:
        st.info("‚ÑπÔ∏è Primero procesa los textos usando el bot√≥n de arriba")
    else:
        # Calcular l√≠mites apropiados seg√∫n el tama√±o del dataset
        n_samples = len(st.session_state.datos)
        n_classes = st.session_state.datos['categoria'].nunique()
        
        # Informaci√≥n sobre el dataset
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä Total Muestras", n_samples)
        with col2:
            st.metric("üè∑Ô∏è Categor√≠as", n_classes)
        with col3:
            min_per_class = st.session_state.datos['categoria'].value_counts().min()
            st.metric("üìâ M√≠nimo/Categor√≠a", min_per_class)
        
        # Advertencias para datasets peque√±os
        if n_samples < 15:
            st.warning(f"""
            ‚ö†Ô∏è **Dataset peque√±o detectado ({n_samples} muestras)**
            
            Para mejores resultados:
            - Se recomienda al menos 15-20 documentos
            - M√≠nimo 3-5 ejemplos por categor√≠a
            - Considera agregar m√°s datos
            """)
        
        # Ajustar l√≠mites del slider
        if n_samples < 10:
            max_test = 40
            default_test = 30
            st.info("‚ÑπÔ∏è Usando 30% para test debido al tama√±o peque√±o del dataset")
        else:
            max_test = 40
            default_test = 20
        
        test_size = st.slider(
            "Porcentaje de datos para prueba:", 
            min_value=10, 
            max_value=max_test, 
            value=default_test, 
            step=5,
            help="""
            - 10-20%: Recomendado para datasets grandes (>100 muestras)
            - 20-30%: Recomendado para datasets medianos (20-100 muestras)
            - 30-40%: Recomendado para datasets peque√±os (<20 muestras)
            """
        ) / 100
        
        if st.button("üöÄ Entrenar Modelo"):
            with st.spinner("Entrenando modelo..."):
                X = st.session_state.vectores
                y = st.session_state.datos['categoria'].values
                
                modelo = st.session_state.modelo
                metricas = modelo.entrenar_clasificador(X, y, test_size=test_size)
                
                st.session_state.metricas = metricas
                st.session_state.modelo_entrenado = True
                
                # Mostrar resultados
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üéØ Precisi√≥n", f"{metricas['accuracy']:.1%}")
                with col2:
                    st.metric("üìä Categor√≠as", len(metricas['categorias']))
                with col3:
                    st.metric("üìà F1-Score", 
                             f"{metricas['reporte']['weighted avg']['f1-score']:.2f}")
                
                st.success("‚úÖ Modelo entrenado exitosamente")
                
                # Reporte detallado
                with st.expander("üìã Ver Reporte Detallado"):
                    for cat in metricas['categorias']:
                        st.write(f"**{cat}:**")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Precision", 
                                    f"{metricas['reporte'][cat]['precision']:.2f}")
                        with col2:
                            st.metric("Recall", 
                                    f"{metricas['reporte'][cat]['recall']:.2f}")
                        with col3:
                            st.metric("F1-Score", 
                                    f"{metricas['reporte'][cat]['f1-score']:.2f}")


def pagina_prediccion():
    """P√°gina para hacer predicciones con el modelo"""
    st.header("üîÆ Predicci√≥n de Categor√≠as")
    
    if not st.session_state.modelo_entrenado:
        st.warning("‚ö†Ô∏è Primero debes entrenar el modelo en la secci√≥n 'Entrenamiento'")
        return
    
    st.subheader("Ingresa un nuevo texto para clasificar")
    
    texto_nuevo = st.text_area(
        "Texto a clasificar:",
        height=150,
        placeholder="Escribe o pega aqu√≠ el texto que quieres clasificar..."
    )
    
    if st.button("üéØ Predecir Categor√≠a"):
        if texto_nuevo:
            with st.spinner("Analizando texto..."):
                # Preprocesar
                prep = st.session_state.preprocesador
                texto_procesado = prep.procesar_texto(texto_nuevo)
                
                # Vectorizar
                vector = prep.vectorizer.transform([texto_procesado])
                
                # Predecir
                modelo = st.session_state.modelo
                prediccion, probabilidades = modelo.predecir_con_probabilidad(vector)
                
                # Mostrar resultado
                st.success(f"‚úÖ Categor√≠a Predicha: **{prediccion[0]}**")
                
                # Mostrar probabilidades
                st.subheader("üìä Probabilidades por Categor√≠a")
                
                prob_df = pd.DataFrame({
                    'Categor√≠a': modelo.categorias,
                    'Probabilidad': probabilidades[0]
                })
                prob_df = prob_df.sort_values('Probabilidad', ascending=False)
                
                fig = px.bar(prob_df, x='Categor√≠a', y='Probabilidad',
                           title='Distribuci√≥n de Probabilidades',
                           color='Probabilidad',
                           color_continuous_scale='Blues')
                st.plotly_chart(fig, use_container_width=True)
                
                # Mostrar texto procesado
                with st.expander("Ver texto procesado"):
                    st.write(texto_procesado)
        else:
            st.warning("‚ö†Ô∏è Por favor ingresa un texto")


def pagina_analisis():
    """P√°gina de an√°lisis y visualizaciones"""
    st.header("üìä An√°lisis y Visualizaciones")
    
    if st.session_state.datos is None:
        st.warning("‚ö†Ô∏è No hay datos disponibles para analizar")
        return
    
    df = st.session_state.datos
    
    # Estad√≠sticas generales
    st.subheader("üìà Estad√≠sticas Generales")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìÑ Total Documentos", len(df))
    with col2:
        st.metric("üìù Total Palabras", int(df['longitud'].sum()))
    with col3:
        st.metric("üìä Promedio Palabras", int(df['longitud'].mean()))
    with col4:
        if 'categoria' in df.columns:
            st.metric("üè∑Ô∏è Categor√≠as", df['categoria'].nunique())
    
    st.divider()
    
    # Distribuci√≥n de longitudes
    st.subheader("üìè Distribuci√≥n de Longitud de Documentos")
    fig = px.histogram(df, x='longitud', nbins=20,
                      title='Distribuci√≥n de Palabras por Documento')
    st.plotly_chart(fig, use_container_width=True)
    
    # Distribuci√≥n por categor√≠a (si existe)
    if 'categoria' in df.columns:
        st.divider()
        st.subheader("üè∑Ô∏è Distribuci√≥n por Categor√≠a")
        
        cat_counts = df['categoria'].value_counts()
        fig = px.pie(values=cat_counts.values, names=cat_counts.index,
                    title='Proporci√≥n de Documentos por Categor√≠a')
        st.plotly_chart(fig, use_container_width=True)
    
    # M√©tricas del modelo (si est√° entrenado)
    if st.session_state.modelo_entrenado:
        st.divider()
        st.subheader("ü§ñ M√©tricas del Modelo")
        
        metricas = st.session_state.metricas
        
        # Gr√°fico de m√©tricas por categor√≠a
        categorias = metricas['categorias']
        precision_vals = [metricas['reporte'][cat]['precision'] for cat in categorias]
        recall_vals = [metricas['reporte'][cat]['recall'] for cat in categorias]
        f1_vals = [metricas['reporte'][cat]['f1-score'] for cat in categorias]
        
        fig = go.Figure()
        fig.add_trace(go.Bar(x=categorias, y=precision_vals, name='Precision'))
        fig.add_trace(go.Bar(x=categorias, y=recall_vals, name='Recall'))
        fig.add_trace(go.Bar(x=categorias, y=f1_vals, name='F1-Score'))
        
        fig.update_layout(
            title='M√©tricas del Modelo por Categor√≠a',
            barmode='group',
            xaxis_title='Categor√≠a',
            yaxis_title='Valor'
        )
        st.plotly_chart(fig, use_container_width=True)


def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    inicializar_sesion()
    
    # Sidebar
    st.sidebar.title("üåê Navegaci√≥n")
    st.sidebar.markdown("---")
    
    pagina = st.sidebar.radio(
        "Selecciona una secci√≥n:",
        ["üè† Inicio", 
         "üì• Extracci√≥n de Datos", 
         "ü§ñ Entrenamiento",
         "üîÆ Predicci√≥n",
         "üìä An√°lisis"]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.info("""
    **Sistema de Aprendizaje Web**
    
    Proyecto acad√©mico que demuestra:
    - Web Scraping
    - Procesamiento NLP
    - Machine Learning
    - Aplicaci√≥n Streamlit
    """)
    
    # Renderizar p√°gina seleccionada
    if "Inicio" in pagina:
        pagina_inicio()
    elif "Extracci√≥n" in pagina:
        pagina_extraccion()
    elif "Entrenamiento" in pagina:
        pagina_entrenamiento()
    elif "Predicci√≥n" in pagina:
        pagina_prediccion()
    elif "An√°lisis" in pagina:
        pagina_analisis()


if __name__ == "__main__":
    main()
